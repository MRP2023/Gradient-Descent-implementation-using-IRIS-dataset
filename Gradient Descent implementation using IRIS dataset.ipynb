{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c551379b-3de0-48bd-98e6-df31c206cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9becb79d-2a41-473e-af7d-f73c15bbd247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'published_in': 'Significance, 2021', 'year': 2021, 'url': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'doi': '1740-9713.01589'}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
      "     sepal length  sepal width  petal length  petal width\n",
      "0             5.1          3.5           1.4          0.2\n",
      "1             4.9          3.0           1.4          0.2\n",
      "2             4.7          3.2           1.3          0.2\n",
      "3             4.6          3.1           1.5          0.2\n",
      "4             5.0          3.6           1.4          0.2\n",
      "..            ...          ...           ...          ...\n",
      "145           6.7          3.0           5.2          2.3\n",
      "146           6.3          2.5           5.0          1.9\n",
      "147           6.5          3.0           5.2          2.0\n",
      "148           6.2          3.4           5.4          2.3\n",
      "149           5.9          3.0           5.1          1.8\n",
      "\n",
      "[150 rows x 4 columns]               class\n",
      "0       Iris-setosa\n",
      "1       Iris-setosa\n",
      "2       Iris-setosa\n",
      "3       Iris-setosa\n",
      "4       Iris-setosa\n",
      "..              ...\n",
      "145  Iris-virginica\n",
      "146  Iris-virginica\n",
      "147  Iris-virginica\n",
      "148  Iris-virginica\n",
      "149  Iris-virginica\n",
      "\n",
      "[150 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fetch dataset\n",
    "iris = fetch_ucirepo(id=53)\n",
    "\n",
    "# data (as pandas dataframes) \n",
    "X = iris.data.features \n",
    "y = iris.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(iris.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7ed95f-13a8-4885-9923-adcfba5a1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.concat([X,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b57556-c07e-440f-94db-dfb4a83065b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              class\n",
      "0       Iris-setosa\n",
      "1       Iris-setosa\n",
      "2       Iris-setosa\n",
      "3       Iris-setosa\n",
      "4       Iris-setosa\n",
      "..              ...\n",
      "145  Iris-virginica\n",
      "146  Iris-virginica\n",
      "147  Iris-virginica\n",
      "148  Iris-virginica\n",
      "149  Iris-virginica\n",
      "\n",
      "[150 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5794264f-34f8-4c1a-bf4b-43db88e2cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the target variable\n",
    "y_encoded = label_encoder.fit_transform(y['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0891f191-8881-4834-99e8-31fb2443db4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba1fa4e-38ef-4d2e-8d8a-ff035d43172a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49917515-b38f-4f76-902a-2ea8acf84b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5acfa6e4-83bc-4b97-a494-55db27ad3927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the SGDClassifier with 'log_loss' as the loss function\n",
    "model = SGDClassifier(loss='log_loss', max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5fb5a5b-0e70-4a48-80f3-9dd414e7b927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between Actual and Predicted:\n",
      "    Actual  Predicted\n",
      "0        1          1\n",
      "1        0          0\n",
      "2        2          2\n",
      "3        1          1\n",
      "4        1          1\n",
      "5        0          0\n",
      "6        1          0\n",
      "7        2          2\n",
      "8        1          1\n",
      "9        1          1\n",
      "10       2          2\n",
      "11       0          0\n",
      "12       0          0\n",
      "13       0          0\n",
      "14       0          0\n",
      "15       1          0\n",
      "16       2          2\n",
      "17       1          1\n",
      "18       1          1\n",
      "19       2          2\n",
      "20       0          0\n",
      "21       2          2\n",
      "22       0          0\n",
      "23       2          2\n",
      "24       2          2\n",
      "25       2          2\n",
      "26       2          2\n",
      "27       2          2\n",
      "28       0          0\n",
      "29       0          0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Compare y_test and y_pred\n",
    "comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "# Display the comparison DataFrame\n",
    "print(\"Comparison between Actual and Predicted:\")\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc6990da-bbfd-49cf-9c7f-ba0d50c62d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 2  7  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "569dd068-67e6-40c8-b62f-e923398c3405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       0.83      1.00      0.91        10\n",
      "Iris-versicolor       1.00      0.78      0.88         9\n",
      " Iris-virginica       1.00      1.00      1.00        11\n",
      "\n",
      "       accuracy                           0.93        30\n",
      "      macro avg       0.94      0.93      0.93        30\n",
      "   weighted avg       0.94      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate and display a classification report\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
